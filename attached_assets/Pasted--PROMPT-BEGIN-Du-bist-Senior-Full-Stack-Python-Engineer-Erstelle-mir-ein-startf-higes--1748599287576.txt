### PROMPT-BEGIN ###

Du bist Senior-Full-Stack-Python-Engineer.  
Erstelle mir ein startfÃ¤higes Replit-Projekt namens **neuralex-platform** mit folgendem Funktionsumfang â¬‡ï¸

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ”¹ 1 Â· TECHNOLOGIE-STACK
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Python 3.11  
â€¢ FastAPI + Uvicorn (REST API)  
â€¢ Redis (Job-Queue)  
â€¢ SQLAlchemy + PostgreSQL (Cloud SQL)  
â€¢ Requests/HTTPX (Call zum externen ML-Server auf Hetzner)  
â€¢ Pydantic (Schemas / Validation)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ”¹ 2 Â· VERZEICHNIS- & DATEISTRUKTUR
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
root/
â”‚
â”œâ”€â”€ .replit                  # Startbefehl
â”œâ”€â”€ replit.nix               # System-Packages
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI-Entrypoint
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ gcp_fetcher.py   # holt JSON aus GCP-Bucket
â”‚   â”œâ”€â”€ ml_client/
â”‚   â”‚   â””â”€â”€ predict.py       # POST /plain_text an Hetzner-Server
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ data_types.py    # aus dataTypes.json generiert
â”‚   â”‚   â”œâ”€â”€ doc_types.py     # aus docTypes.json generiert
â”‚   â”‚   â””â”€â”€ event_types.py   # aus eventTypes.json generiert
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy-ORM
â”‚   â”‚   â””â”€â”€ session.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ mapping.py       # helper, labelâ†”ï¸id-Mapping
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_endpoints.py
â”‚
â””â”€â”€ README.md

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ”¹ 3 Â· INHALT WICHTIGER DATEIEN (Ausschnitte)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ“„ **.replit**
run = "uvicorn app.main:app --host 0.0.0.0 --port 8080"

ðŸ“„ **replit.nix**
{ pkgs }: {
  deps = [
    pkgs.python311
    pkgs.redis
  ];
}

ðŸ“„ **app/main.py**
"""
FastAPI-App mit:
  â€“ /health          GET   -> {"status": "ok"}
  â€“ /ingest          POST  -> nimmt {gcs_uri:str} oder {payload:dict}
  â€“ ruft async gcp_fetcher.fetch()
  â€“ pushed Job in Redis-Queue (key: 'doc_jobs')
  â€“ background-worker konsumiert, ruft ml_client.predict(), speichert Ergebnis in DB
"""

ðŸ“„ **app/ingestion/gcp_fetcher.py**
"""
fetch(gcs_uri) -> dict
Verwendet google-cloud-storage-Client (place holder fÃ¼r creds).
"""

ðŸ“„ **app/ml_client/predict.py**
"""
async def predict(job_payload: dict) -> dict:
    POST http://ML_SERVER/predict
    RÃ¼ckgabe JSON {doc_type,event_type,entities}
"""

ðŸ“„ **app/db/models.py**
"""
Klassen: Document, Entity  (SQLAlchemy + UUID primary key)
"""

ðŸ“„ **tests/test_endpoints.py**
"""
pytest-Smoke-Test:
  â€“ /health 200
  â€“ /ingest 202 mit Sample-Payload
"""

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ”¹ 4 Â· ABHÃ„NGIGKEITEN (requirements.txt)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fastapi
uvicorn[standard]
pydantic
sqlalchemy
asyncpg
redis
aiohttp
google-cloud-storage
python-dotenv
pytest
httpx

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ”¹ 5 Â· ENV-SECRETS (als Replit-Secrets anlegen)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
POSTGRES_DSN      = "postgresql+asyncpg://user:pass@host:port/db"
REDIS_URL         = "redis://localhost:6379/0"
GCP_BUCKET_NAME   = "neuralex-incoming-json"
ML_SERVER_URL     = "http://<hetzner-ip>:8000"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ”¹ 6 Â· TODO-LISTE (automatisch als Kommentare einfÃ¼gen)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TODO: Implement background-worker mit aioredis Subscriber  
TODO: Add Alembic migrations (optional)  
TODO: Add retry-logic in ml_client.predict()  
TODO: Add /docs (Swagger) with JWT auth stubs  
TODO: Map JSON-Schemas â†’ Pydantic-Models

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Erzeuge alle Dateien inkl. Boiler-Plate-Code, Kommentare und Schritt-fÃ¼r-Schritt Anweisungen im README, wie das Projekt lokal in Replit gestartet wird (redis-server, uvicorn-run).

### PROMPT-END ###
